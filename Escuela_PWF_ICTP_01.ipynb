{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08238731",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"./img/patreon.PNG\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "# Machine Learning (Introducción)\n",
    "## Sesión 1\n",
    "\n",
    "Gabriel Abellán <gabriel.abellan@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fdd7d",
   "metadata": {},
   "source": [
    "En este `notebook` presentaremos algunos términos y técnicas comunes de `machine learning`. Cuando se habla de `Deep Learning`, indicamos un conjunto de herramientas y técnicas de `machine learning` que implican el uso de Redes Neuronales Artificiales.\n",
    "\n",
    "`Machine Learning` es una rama de la inteligencia artificial que desarrolla algoritmos capaces de aprender patrones y reglas utilizando datos. Aunque conceptualmente es una disciplina bien fundamentada ~1950, su reciente uso exahustivo tiene que ver con tres factores:\n",
    "- Desarrollo en la capacidad de almacenamiento a bajo costo.\n",
    "- Desarrollo en la capacidad de computo a bajo costo.\n",
    "- Desarrollo de dispositivos que producen cantidades enormes de datos (teléfonos moviles, webs, sensores, etc).\n",
    "\n",
    "El propósito de este taller es introducir conceptos que (tal vez) son nuevos pero aplicarlos a problemas que (tal vez) ya conocen. De esta manera queremos minimizar el impacto del primer encuentro con el tema y acelerar asi la curva de aprendizaje. Una vez familiarizados con la herramienta, se trata de buscar (o crear) nuevos algoritmos e implementarlos dentro del framework.\n",
    "\n",
    "Los conceptos nuevos tienen que ver con `redes neuronales` y su aplicación; los problemas que trataremos son los viejos y conocidos problemas de `regresión` y `clasificación` (ejemplos de aprendizaje supervisado), así como reducción dimensional haciendo `análisis de componentes principales PCA` (ejemplo de aprendizaje no-supervisado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee58fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72425b",
   "metadata": {},
   "source": [
    "## Apredizaje Supervisado\n",
    "### Modelo Lineal - Regresión\n",
    "\n",
    "Tenemos una data sobre personas que incluye: género, altura y peso. Deseamos hacer un modelo simple que permita predecir el peso en función de la altura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef88109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'https://gitlab.com/gabriel.abellan/machine-learning-la-conga/-/raw/main/datasets/weight-height.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf70b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()   # tambien es posible obtener informacion usando df.describe()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6250dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='Height',\n",
    "        y='Weight', title='Weight Vs. Height in Adults',\n",
    "        alpha=.4)\n",
    "plt.plot([55,78], [75,250], color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e6561",
   "metadata": {},
   "source": [
    "definimos una función para construir la ecuación de una recta 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, w=0, b=0):\n",
    "    return x*w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48df078",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(55,80, 101)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e85941",
   "metadata": {},
   "source": [
    "Construimos la ecuación de una recta trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = line(x, w=0, b=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='Height',\n",
    "        y='Weight', title='Weight Vs. Height in Adults',\n",
    "        alpha=.4)\n",
    "plt.plot(x, yhat, color='red', linewidth=2, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f19bc",
   "metadata": {},
   "source": [
    "Probamos variando $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfa85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='Height',\n",
    "        y='Weight', title='Weight Vs. Height in Adults',\n",
    "        alpha=.4)\n",
    "plt.plot(x, line(x, b=50), color='orange', linewidth=2, alpha=.5)\n",
    "plt.plot(x, line(x, b=150), color='red', linewidth=2, alpha=.5)\n",
    "plt.plot(x, line(x, b=250), color='black', linewidth=2, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7477bf",
   "metadata": {},
   "source": [
    "Probamos variando $w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92420639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x='Height',\n",
    "        y='Weight', title='Weight Vs. Height in Adults',\n",
    "        alpha=.4)\n",
    "plt.plot(x, line(x, w=5), color='orange', linewidth=2, alpha=.5)\n",
    "plt.plot(x, line(x, w=8), color='red', linewidth=2, alpha=.5)\n",
    "plt.plot(x, line(x, w=-1), color='black', linewidth=2, alpha=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4617d",
   "metadata": {},
   "source": [
    "Es posible describir la data encontrando un buen juego de parametros $(w,b)$\n",
    "\n",
    "Definimos una función para calcular el error cuadrático medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    s = (y_true - y_pred)**2\n",
    "    return s.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f89290d",
   "metadata": {},
   "source": [
    "Queremos hacer un modelo donde se predice el peso de un sujeto usando como predictor la altura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6048f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Height']].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df['Weight'].values\n",
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528b1a9",
   "metadata": {},
   "source": [
    "Usando el modelo (con los parametros por defecto), calculamos las predicciones para X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae53fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = line(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb6c8c",
   "metadata": {},
   "source": [
    "Calculamos el error entre los datos reales y la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed15e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_01 = mean_squared_error(y_true, y_pred)\n",
    "print('mse: {:.3f}'.format(mse_01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b9495",
   "metadata": {},
   "source": [
    "Ahora comenzamos a variar los parametros de la recta y observamos cómo el MSE va cambiando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = line(X, w=2)\n",
    "print('mse: {:.3f}'.format(mean_squared_error(y_true, y_pred.ravel())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = line(X, w=2, b=20)\n",
    "print('mse: {:.3f}'.format(mean_squared_error(y_true, y_pred.ravel())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6bfbb3",
   "metadata": {},
   "source": [
    "Podemos repetir esto para varios valores de $b$ y graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "df.plot(kind='scatter',\n",
    "       x='Height', y='Weight', ax=ax1,\n",
    "       alpha=.4, title='Weight Vs. Height in Adults')\n",
    "\n",
    "bbs = np.array([-100,-50,0,50,100,150])\n",
    "\n",
    "mses = []\n",
    "for b in bbs:\n",
    "    y_pred = line(X, w=2, b=b)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mses.append(mse)\n",
    "    plt.plot(X, y_pred)\n",
    "    \n",
    "ax2 = plt.subplot(122)\n",
    "plt.plot(bbs, mses, 'o-')\n",
    "plt.title('Cost as a Function of $b$')\n",
    "plt.xlabel('$b$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed6899",
   "metadata": {},
   "source": [
    "Este proceso que hemos realizado acá *con la mano* es lo que hace una libreria como `keras` aprovechando los recursos de `Tensorflow`.\n",
    "\n",
    "En esta presentación hemos decidido usar `keras` de manera que pueda ganarse familiaridad con las herramientas que se utilizan en Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d542351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, input_shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370aa471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=0.8),loss='mse')\n",
    "#model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y_true, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ffd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter',\n",
    "       x='Height', y='Weight',\n",
    "       title='Weight Vs. Height in Adults', alpha=.4)\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B = model.get_weights()\n",
    "w = W[0,0]; b = B[0];\n",
    "print(model.get_weights())\n",
    "print('w = {:.2f}\\nb = {:.2f}'.format(w,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8c205",
   "metadata": {},
   "source": [
    "Para evaluar modelos de regresión se utiliza la metrica $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b746de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04527124",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r2_score(y_true, y_pred)\n",
    "print('The R^2 score is {:.3f}'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d89f73",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Podemos usar la librería `sklearn` para implementar el procedimiento de `Cross Validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a18ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68791649",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_true, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4dd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929941b",
   "metadata": {},
   "source": [
    "Reseteamos los parámetros para volver a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resetWeights = [np.array([[1.]]), np.array([0.])]\n",
    "model.set_weights(resetWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train).ravel()\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf41a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test).ravel()\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027609d",
   "metadata": {},
   "source": [
    "Evaluamos el performance ahora usando `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83590ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b978db",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = mse(y_train, y_train_pred)\n",
    "print('Mean Squared Error (Train Set):\\t', '{:0.1f}'.format(err))\n",
    "\n",
    "err = mse(y_test, y_test_pred)\n",
    "print('Mean Squared Error (Test Set):\\t', '{:0.1f}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train, y_train_pred)\n",
    "print('R2 score (Train Set):\\t', '{:0.3f}'.format(r2))\n",
    "\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print('R2 score (Test Set):\\t', '{:0.3f}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def5be4",
   "metadata": {},
   "source": [
    "Es posible usar `history` y observar el comportamiento del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dce100",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = pd.DataFrame(history.history).max()\n",
    "(pd.DataFrame(history.history)/max_val).plot(figsize=(9,5))\n",
    "#plt.gca().set_ylim(0.99, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31e25ce",
   "metadata": {},
   "source": [
    "Como suele ser la norma, el algoritmo se desempeña mejor sobre el conjunto de entrenamiento que sobre el conjunto de prueba.\n",
    "\n",
    "Es importante estar atento porque una señal característica de `overfitting` \n",
    "es cuando el desempeno continua mejorando sobre el conjunto de entrenamiento\n",
    "pero se hace peor en el conjunto de prueba. Si esto ocurre hay que revisar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b394c78",
   "metadata": {},
   "source": [
    "## Apredizaje Supervisado\n",
    "### Modelo Lineal - Clasificación Binaria\n",
    "\n",
    "Queremos predecir si un usuario de cierta página web comprará un producto, usando como dato el tiempo que pasa en la página del producto. La etiqueta es binaria (compró: 1, no compró: 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'https://gitlab.com/gabriel.abellan/machine-learning-la-conga/-/raw/main/datasets/user_visit_duration.csv'\n",
    "\n",
    "df_buy = pd.read_csv(data_path)\n",
    "df_buy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6267246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy.plot(kind='scatter',x='Time (min)', y='Buy',\n",
    "           figsize=(8,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75ccc4",
   "metadata": {},
   "source": [
    "Definimos las variables predictivas y el tárget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_buy['Time (min)']\n",
    "y = df_buy['Buy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419b9ce",
   "metadata": {},
   "source": [
    "Probamos usar el mismo modelo (arquitectura) que usamos en el ejemplo anterior. Para ello reinicializamos los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "resetWeights = [np.array([[1.]]), np.array([0.])]\n",
    "model.set_weights(resetWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db51954",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "df_buy.plot(kind='scatter', x='Time (min)', y='Buy',\n",
    "           title='Linear Fit (Miserably Fail)')\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cc0b1",
   "metadata": {},
   "source": [
    "Como puedes ver no tiene mucho sentido utilizar una línea recta para predecir un resultado que sólo puede arrojar valores 0 o 1. Observando esto, la modificación que tenemos que aplicar a nuestro modelo para que funcione es en realidad bastante sencilla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c97f04",
   "metadata": {},
   "source": [
    "### Regresión Logístisca\n",
    "\n",
    "Abordaremos este problema con un método llamado Regresíon Logística. A pesar de que su nombre es \"regresión\", esta técnica es realmente útil para resolver problemas de clasificación, es decir, problemas en los que el resultado es discreto.\n",
    "\n",
    "La técnica de regresión lineal que acabamos de aprender predice valores en el eje real para cada punto de datos de entrada. Podemos modificar la forma de la hipótesis para poder predecir la probabilidad de un resultado para cada valor de la entrada. De esta forma nuestro modelo daría un valor entre 0 y 1. En ese punto podríamos utilizar p = 0.5 como criterio de separación y asignar cada punto predicho con una probabilidad inferior a 0.5 a la clase 0, y cada punto predicho con una probabilidad superior a 0,5 a la clase 1.\n",
    "\n",
    "En otras palabras, si modificamos la hipótesis de regresión para permitir una función no lineal entre el dominio de nuestros datos y el intervalo [0,1], podemos utilizar la misma maquinaria para resolver un problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24569a54",
   "metadata": {},
   "source": [
    "Necesitamos una función no lineal que mapee todo el eje real en el intervalo [0,1]. Hay muchas funciones de este tipo. Una función simple, suave y que se comporta bien es la `sigmoide`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a217d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1./(1. + np.exp(-z))\n",
    "\n",
    "z = np.arange(-10, 10, 0.1)\n",
    "\n",
    "plt.plot(z, sigmoid(z), color='blue')\n",
    "plt.title('Sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05554c38",
   "metadata": {},
   "source": [
    "Usando la sigmoide podemos formular la hipótesis para el problema de clasificación\n",
    "\n",
    "$\\mbox{Comprar} = \\frac{1}{1+e^{-(tw+b})} = \\hat{y}$\n",
    "\n",
    "La sigmoide se utiliza generalmente para la capa de salida en las redes de clasificación. No suele usarse entre capas internas porque hay otras funciones que se comportan mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fed9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "ws = [.1, .3, 1., 3.]\n",
    "for w in ws:\n",
    "    plt.plot(x, sigmoid(line(x, w)))\n",
    "    \n",
    "plt.legend(ws)\n",
    "plt.title('Changing $w$')\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "bs = [-5, 0, 5]\n",
    "for b in bs:\n",
    "    plt.plot(x, sigmoid(line(x, w=1, b=b)))\n",
    "    \n",
    "plt.legend(bs)\n",
    "plt.title('Changing $b$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619dd7e",
   "metadata": {},
   "source": [
    "### Función de Costo (loss)\n",
    "\n",
    "Es necesario ajustar la definición de la función de coste para que tenga sentido para un problema de clasificación binaria. Hay varias opciones para ello, de forma similar al caso de la regresión, incluyendo `square loss`, `hinge loss` y `logistic loss`.\n",
    "\n",
    "Los modelos de *Deep Learning* aprenden minimizando la función costo. Esto requiere que la función tenga dicho mínimo en primer lugar. En matemáticas, esto quiere decir que la función de coste debe ser convexa y diferenciable.\n",
    "\n",
    "Una de las funciones de costo mas usadas en *Deep Learning* es `cross entropy`. Esta se define como\n",
    "\n",
    "$ C_i = -y_i \\ln(\\hat{y}_i) - (1 - y_i) \\ln(1 - \\hat{y}_i) $\n",
    "\n",
    "Dado que $y$ únicamente puede ser 0 o 1, sólo uno de los términos aparece al evaluar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8056c",
   "metadata": {},
   "source": [
    "Si $y_i = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, -np.log(1-sigmoid(z)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6eb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(z, -np.log(1-sigmoid(z)))\n",
    "axs[0].set_title('$y = 0$')\n",
    "axs[1].plot(z, -np.log(sigmoid(z)))\n",
    "axs[1].set_title('$y = 1$')\n",
    "\n",
    "fig.suptitle('Cross Entropy by Case');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8acc1",
   "metadata": {},
   "source": [
    "Una vez definida para un solo punto, el promedio de la función costo es\n",
    "\n",
    "$ c = \\displaystyle{\\frac{1}{N} \\sum_i c_i }$\n",
    "\n",
    "Esta función puede generalizarse a problemas con múltiples clases. Para ello puede usarse la función `softmax` como generalización de la `sigmoide` y como función costo `categorical cross entropy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3b309",
   "metadata": {},
   "source": [
    "A continuación definimos nuestro modelo usando `Keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8275e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = Sequential()\n",
    "logistic.add(Dense(1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b22eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc4057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7461ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, logistic.predict(z))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.compile(optimizer=SGD(learning_rate=.5),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e674967",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.fit(X, y, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_buy.plot(kind='scatter', x='Time (min)', y='Buy',\n",
    "                title='Purchase Vs. Time spent on site')\n",
    "\n",
    "temp = np.linspace(0,4)\n",
    "ax.plot(temp, logistic.predict(temp), color='orange')\n",
    "plt.legend(['model', 'data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25758c",
   "metadata": {},
   "source": [
    "Notar que la regresión logística produce una probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic.predict(X)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f4731",
   "metadata": {},
   "source": [
    "Si queremos una predicción binaria, podemos imponer un umbral a los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin = y_pred > .5\n",
    "y_pred_bin[:5].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ee6ab",
   "metadata": {},
   "source": [
    "Usando este arreglo podemos calcular el `accuracy` del modelo. Recordamos que `accuracy` es \n",
    "\n",
    "$$\\mbox{Acc} = \\dfrac{TP + TN}{\\mbox{All}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a929a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, y_pred_bin)\n",
    "print('Accuracy Score: {:.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7dc79",
   "metadata": {},
   "source": [
    "A continuación realizamos el proceso de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1:4].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = logistic.get_weights()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [np.zeros(w.shape) for w in params]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.set_weights(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, logistic.predict(X) > .5)\n",
    "print('Accuracy Score: {:.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba513b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, logistic.predict(z));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = logistic.fit(X_train, y_train, epochs=25, verbose=0, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_class = logistic.predict(X_train) > .5\n",
    "acc = accuracy_score(y_train, y_train_pred_class)\n",
    "print('Train Accuracy Score: {:0.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_class = logistic.predict(X_test) > .5\n",
    "acc = accuracy_score(y_test, y_test_pred_class)\n",
    "print('Test Accuracy Score: {:0.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93fc303",
   "metadata": {},
   "source": [
    "Podemos ver algunas predicciones en términos de probabilidades evaluando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:5]\n",
    "y_prob = logistic.predict(X_new)\n",
    "\n",
    "for n in range(X_new.size): \n",
    "    print('Para un tiempo de {:.3f} la probabilidad de comprar es {:.2f}.'.format(X_new.values[n], y_prob[n,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670fe60",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Aunque tuviéramos mucho cuidado al dividir nuestros datos de forma aleatoria, esa es sólo una de las muchas formas posibles de realizar una partición de la data. ¿Qué pasaría si realizáramos varias particiones diferentes de entrenamiento/prueba, comprobáramos la puntuación de la prueba en cada una de ellas y, finalmente, promediáramos las puntuaciones? No sólo tendríamos una estimación más precisa del `accuracy` real, sino que también podríamos calcular la desviación estándar de las puntuaciones y, por lo tanto, conocer el error en el `accuracy`. Este proceso se conoce como `cross-validation` y la forma usual de implementarlo es a traves de `K-fold cross-validation`.\n",
    "\n",
    "En `K-fold cross-validation`, el conjunto de datos se divide en `K` subconjuntos aleatorios de igual tamaño. Entonces, cada uno de los `K` subconjuntos desempeña el papel de conjunto de prueba, mientras que los demás se agregan para formar un conjunto de entrenamiento. De este modo, obtenemos `K` estimaciones de la puntuación del modelo, cada una calculada a partir de un conjunto de pruebas que no se solapa con ninguno de los otros conjuntos de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d286dc",
   "metadata": {},
   "source": [
    "`Scikit-Learn` ofrece `cross-validation` de forma inmediata, pero tendremos que usar un `wrapper` para nuestro modelo y que de esta manera pueda ser entendida por `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e20c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19215f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic():\n",
    "    logistic = Sequential()\n",
    "    logistic.add(Dense(1, input_dim=1,\n",
    "                      activation='sigmoid'))\n",
    "    logistic.compile(optimizer=SGD(learning_rate=.5),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = KerasClassifier(model=build_logistic,\n",
    "                          epochs=25, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a11456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f4acf",
   "metadata": {},
   "source": [
    "Necesitamos poner en forma apropiada el data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshape = X.values.reshape(-1,1)\n",
    "y_reshape = y.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ded83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(3, shuffle=True)\n",
    "scores = cross_val_score(logistic, X_reshape, y_reshape, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fde50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = scores.mean()\n",
    "s = scores.std(ddof=1)\n",
    "\n",
    "print('Cross Validation Accuracy:',\n",
    "     '{:.4f} ± {:.4f}'.format(m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c731576",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "¿Es `accuracy` la mejor manera de comprobar el rendimiento de nuestro modelo? Nos dice lo bien que lo estamos haciendo en general, pero no nos da ninguna idea del tipo de errores que está cometiendo el modelo. Veamos como podemos hacerlo mejor.\n",
    "\n",
    "En el problema que acabamos de introducir, estamos estimando la probabilidad de compra a partir del tiempo de permanencia en una pagina. Se trata de una clasificacion binaria, y podemos acertar o equivocarnos en las cuatro formas representadas aqui:\n",
    "\n",
    "<div>\n",
    "    <img src=\"./img/con_mat.PNG\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Esta tabla se llama matriz de confusión y da una mejor compresión de las predicciones correctas e incorrectas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_pred_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17badc8",
   "metadata": {},
   "source": [
    "Hacemos un poquito de *make-up* para presentarla mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_cm(y_true, y_pred, labels=['False', 'True']):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    pred_labels = ['Predicted ' + l for l in labels]\n",
    "    \n",
    "    df = pd.DataFrame(cm, index=labels,\n",
    "                     columns=pred_labels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_cm(y, y_pred_bin, ['Not Buy', 'Buy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0206f59",
   "metadata": {},
   "source": [
    "Otras métricas para medir el performance son\n",
    "\n",
    "- `Precision`\n",
    "- `Recall`\n",
    "- `F1`\n",
    "\n",
    "Sus definiciones son: \n",
    "$$\\mbox{P} = \\dfrac{T\\!P}{T\\!P+F\\!P}$$\n",
    "\n",
    "$$\\mbox{R} = \\dfrac{T\\!P}{T\\!P+F\\!N}$$\n",
    "\n",
    "$$\\mbox{F1} = \\dfrac{2}{\\frac{1}{\\mbox{P}} + \\frac{1}{\\mbox{R}}} = 2\\dfrac{\\mbox{P R}}{\\mbox{P + R}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b22b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y, y_pred_bin)\n",
    "print('Precision:\\t{:.3f}'.format(precision))\n",
    "\n",
    "recall = recall_score(y, y_pred_bin)\n",
    "print('Recall: \\t{:.3f}'.format(recall))\n",
    "\n",
    "f1 = f1_score(y, y_pred_bin)\n",
    "print('F1 Score: \\t{:.3f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c663cc5",
   "metadata": {},
   "source": [
    "## Algunas operaciones comunes que podemos hacer para cambiar la representación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca45d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Gender'], prefix='Gender').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af679553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Height (feet)'] = df['Height']/12.\n",
    "df['Weight (100 lbs)'] = df['Weight']/100.\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f61ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "df['Weight_mms'] = mms.fit_transform(df[['Weight']])\n",
    "df['Height_mms'] = mms.fit_transform(df[['Height']])\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "df['Weight_ss'] = ss.fit_transform(df[['Weight']])\n",
    "df['Height_ss'] = ss.fit_transform(df[['Height']])\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "for (i, feature) in enumerate(['Height', \n",
    "                               'Height (feet)', \n",
    "                               'Height_mms', \n",
    "                               'Height_ss']):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    df[feature].plot(kind='hist', title=feature)\n",
    "    plt.xlabel(feature)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5c66a",
   "metadata": {},
   "source": [
    "### Ejercicio 1:\n",
    "\n",
    "- cargar la data `housing-data.csv` (*aquí la data* <https://gitlab.com/gabriel.abellan/machine-learning-la-conga/-/raw/main/datasets/housing-data.csv>)\n",
    "- graficar los histogramas para cada feature\n",
    "- crear dos variables `X`, `y`: `X` debe ser una matriz con tres columnas (sqft, bdrms, age); `y` debe ser un vector con una columna (price)\n",
    "- configurar un modelo en Keras para hacer un ajuste lineal (tener cuidado del número apropiado de inputs y outputs)\n",
    "- dividir la data en `train` y `test`\n",
    "- entrenar el modelo usando el conjunto `train` y contrastar el desempeño obtenido tanto con `train` como con `test`\n",
    "- ¿cómo se comporta el modelo?\n",
    "- trata de mejorar el modelo realizando alguna de las siguientes acciones:\n",
    "    - normalizar los inputs con algunas de los metodos mencionados\n",
    "    - usa un valor de `learning rate` diferente\n",
    "    - usar un `optimizer` distinto\n",
    "- cuando estés satisfecho con el resultado, calcula el valor $R^2$ sobre el `test`\n",
    "\n",
    "**Opcional 1**\n",
    "\n",
    "Una vez que has encontrado un modelo con el cual estás satisfecho, es posible hacer un test simple y convincente para determinar cuán bueno es el performance del modelo. La idea es la siguiente:\n",
    "- Tomar el vector `y_train` y realizar una permutación.\n",
    "- Entrenar el modelo usando este nuevo `y_train_nuevo` permutado.\n",
    "- Calcular el `mean_squared_error` (o $R^2$ para efectos del ejercicio es indiferente) y guardarlo en una lista.\n",
    "- Iterar sobre los tres pasos anteriores (100, 1000 veces? Lo que te permita la máquina en un tiempo razonable; razonable quiere decir unos pocos minutos).\n",
    "- Con la lista creada haz un histograma.\n",
    "- Determina la probabilidad de obtener el desempeño original en términos de esta distribución.\n",
    "\n",
    "Lo que hacemos aca es esencialmente un test de hipótesis y lo que estamos respondiendo es cuál es la probabilidad de que el desempeño obtenido inicialmente sea producto del azar.\n",
    "\n",
    "**Opcional 2**\n",
    "\n",
    "Transformar el problema de regresión a un problema de clasificación. La idea es:\n",
    "- Dividir los valores en `y` (price) en categorías. Para ello hay que realizar cortes y asignarles una etiqueta.\n",
    "- Replantear el problema para atacarlo como un problema de clasificacion: decidir la función costo, decidir la métrica, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b79aa",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "El objetivo es predecir la variable `left` usando el resto de la data. Como el target es binario, este es un problema de clasificación.\n",
    "\n",
    "- cargar la data `HR_comma_sep.csv` (*aqui la data* <https://gitlab.com/gabriel.abellan/machine-learning-la-conga/-/raw/main/datasets/HR_comma_sep.csv>). Inspeccionar.\n",
    "- verificar si algún feature necesita reescalamiento.\n",
    "- transformar las variables categóricas usando dummies.\n",
    "- split la data.\n",
    "- jugar con los ajustes del learning rate y el optimizer.\n",
    "- verificar la matriz de confusion, precision y recall.\n",
    "- verificar los resultados usando 5-Fold cross-validation.\n",
    "- ¿es bueno este modelo?\n",
    "\n",
    "***Opcional 1***\n",
    "\n",
    "Para tratar de refinar el modelo podemos tratar de explorar las variables que funcionan mejor como predictores. Podemos usar dos técnicas simples tratando de determinar el grado de correlación.\n",
    "1. Si la correlación es categórica-continua hacemos un modelo logístico exploratorio para el `target` y cada variable numérica que queremos explorar. Si hay correlación, lograremos producir un buen modelo predictivo con ese par.\n",
    "2. Si la correlación es categorica-categorica lo más simple es construir una tabla de contingencia (`cross tabulation`) y detectar de allí si hay alguna correlación.\n",
    "\n",
    "La idea final es quedarse con las variables que produzcan los mejores resultados.\n",
    "- Una vez que hayas reducido el espacio de variables predictivas, contruye un nuevo modelo y compara el performance con el obtenido usando todas las variables.\n",
    "- ¿Qué puedes concluir?\n",
    "\n",
    "***Opcional 2***\n",
    "\n",
    "Otra forma de refinar el modelo es introducir una capa oculta al modelo de clasificación.\n",
    "\n",
    "- Modifica el modelo original (o el de la ***opcion 1***) y agrega una capa (oculta) entre la entrada y la salida. Esta capa sera de la clase `Dense` al igual que las otras que hemos trabajado.\n",
    "- Experimenta con el numero de neuronas de la capa oculta. Investiga sobre las funciones de activación.\n",
    "- Entrena el modelo y compara con los resultados obtenidos en el modelo original.\n",
    "- ¿Qué puedes concluir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1b393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
